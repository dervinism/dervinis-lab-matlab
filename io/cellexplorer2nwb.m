function cellexplorer2nwb(spikeData, nwbFile, options)
% cellexplorer2nwb(spikeData, nwbFile, <outputFile>)
%
% Function converts spike sorting output saved in the CellExplorer
% (https://cellexplorer.org/) format (spikes.cellinfo.mat) to NWB format by
% attaching spike times timeseries data to an exisiting raw NWB file.
%
% Args:
%   spikeData (struct, required, positional): a shape-(1,1) scalar
%     structure with the following fields:
%     files - a cell array of CellExplorer files (spikes.cellinfo.mat)
%       containing spike times of the indicated units in the field
%       existingUnitIDs.
%     startTimes - spike time displacements relative to the start of the
%       full recording file.
%     existingUnitIDs - unit IDs stored in CellExplorer files.
%     newGlobalUnitID - new unit IDs.
%     newGlobalUnitCh - new unit channels (channels can slightly vary
%       between chunk files).
%     chLabels - channel labels (e.g., LCmicro0001).
%     leadLabels - lead labels (e.g., LC).
%     areaLabels - area labels (e.g., Left_Hippocampus).
%   nwbFile (char, required, positional): a shape-(1, n) character array
%     containing the input NWB file name with a full path that needs
%     updating. It must end with '.nwb'.
%   outputFile (char, required, positional): a shape-(1, m) character array
%     containing the name of the updated NWB file in case it is different
%     to the original input file. It must end with '.nwb'.
%
% Returns:
%   None.
%
% Dependencies:
%   matnwb (https://neurodatawithoutborders.github.io/matnwb/)
%
% Authors:
%   Martynas Dervinis (martynas.dervinis@gmail.com).

arguments
  spikeData (1,1) {mustBeA(spikeData,'struct')}
  nwbFile (1,:) {mustBeA(nwbFile,'char'),mustBeVector,endsWith(nwbFile,'.nwb')}
  options.outputFile (1,:) {mustBeA(options.outputFile,'char'),mustBeVector,endsWith(options.outputFile,'.nwb')} = '';
end

% Parse input
if isempty(options.outputFile)
  options.outputFile = nwbFile;
end

% Load spiking data and convert it
nUnits = numel(spikeData.existingUnitIDs);
loadedFile = '';
spikesConv = struct();
for iUnit = 1:nUnits
  fileToLoad = spikeData.files{iUnit};
  if ~strcmpi(loadedFile,fileToLoad)
    load(fileToLoad); %#ok<*LOAD>
  end
  unitIndExisting = find(spikeData.existingUnitIDs(iUnit) == spikes.cluID);
  unitIndNew = spikeData.newGlobalUnitIDs(iUnit);
  if iUnit == 1 || unitIndNew > numel(spikesConv.cluID)
    spikesConv.times{unitIndNew} = spikes.times{unitIndExisting} + spikeData.startTimes(unitIndExisting);
    spikesConv.cluID{unitIndNew} = unitIndNew;
    spikesConv.maxWaveformCh1{unitIndNew} = spikeData.newGlobalUnitCh(iUnit)+1;
    spikesConv.filtWaveform{unitIndNew} = ...
      spikes.rawWaveform_all{unitIndExisting}(spikesConv.maxWaveformCh1{unitIndNew},:);
    spikesConv.filtWaveformSD{unitIndNew} = spikes.rawWaveform_std{unitIndExisting};
    spikesConv.labels{unitIndNew} = spikes.labels{unitIndExisting};
    spikesConv.chLabels{unitIndNew} = spikeData.chLabels{iUnit};
    spikesConv.areaLabels{unitIndNew} = spikeData.areaLabels{iUnit};
  elseif unitIndNew == numel(spikesConv.cluID)
    spikesConv.times{unitIndNew} = [spikesConv.times{unitIndNew}; ...
      spikes.times{unitIndExisting} + spikeData.startTimes(unitIndExisting)];
    spikesConv.cluID{unitIndNew} = unitIndNew;
    spikesConv.maxWaveformCh1{unitIndNew} = spikeData.newGlobalUnitCh(iUnit)+1;
    spikesConv.filtWaveform{unitIndNew} = ...
      spikes.rawWaveform_all{unitIndExisting}(spikesConv.maxWaveformCh1{unitIndNew},:);
    spikesConv.filtWaveformSD{unitIndNew} = spikes.rawWaveform_std{unitIndExisting};
    spikesConv.labels{unitIndNew} = spikes.labels{unitIndExisting};
    spikesConv.chLabels{unitIndNew} = spikeData.chLabels{iUnit};
    spikesConv.leadLabels{unitIndNew} = spikeData.leadLabels{iUnit};
    spikesConv.areaLabels{unitIndNew} = spikeData.areaLabels{iUnit};
  else
    error('Unit IDs are not expected to decrease.');
  end
end

% Load NWB data
nwb = nwbRead(nwbFile);
electrodesTable = nwb.general_extracellular_ephys_electrodes.toTable();

% Obtain additional channel info
nUnits = numel(spikesConv.cluID);
for iUnit = 1:nUnits
  spikesConv.channelInds{iUnit} = find(ismember(electrodesTable.ChName, spikesConv.chLabels{iUnit}));
  spikesConv.x{iUnit} = electrodesTable.x(spikesConv.channelInds{iUnit});
  spikesConv.y{iUnit} = electrodesTable.y(spikesConv.channelInds{iUnit});
  spikesConv.z{iUnit} = electrodesTable.z(spikesConv.channelInds{iUnit});
  spikesConv.group{iUnit} = electrodesTable.group_name{spikesConv.channelInds{iUnit}};
end

% Create units table
dataDescription = 'Single unit activity';
[spike_times_vector, spike_times_index] = util.create_indexed_column( ...
  spikesConv.times, dataDescription);

nwb.units = types.core.Units( ...
  'colnames', { ... % Provide the column order. All column names have to be defined below
    'cluster_id','type', 'peak_channel_index','peak_channel_id','x','y','z', ...
    'area','lead_id','electrode_group','spike_times','spike_times_index'}, ...
  'description', 'Units table', ...
  'id', types.hdmf_common.ElementIdentifiers( ...
    'data', int64(0:numel(spikesConv.cluID) - 1)), ...
  'cluster_id', types.hdmf_common.VectorData( ...
    'data', cell2mat(spikesConv.cluID), ...
    'description', 'Unique cluster id'), ...
  'type', types.hdmf_common.VectorData( ...
    'data', spikesConv.labels, ...
    'description', 'Cluster type: unit vs mua'), ...
  'peak_channel_index', types.hdmf_common.VectorData( ...
    'data', cell2mat(spikesConv.channelInds), ...
    'description', 'Peak channel row index in the electrode table'), ...
  'peak_channel_id', types.hdmf_common.VectorData( ...
    'data', spikesConv.chLabels, ...
    'description', 'Unique ID of the channel with the largest cluster waveform amplitude'), ...
  'x', types.hdmf_common.VectorData( ...
    'data', cell2mat(spikesConv.x), ...
    'description', 'x coordinate'), ...
  'y', types.hdmf_common.VectorData( ...
    'data', cell2mat(spikesConv.y), ...
    'description', 'y coordinate'), ...
  'z', types.hdmf_common.VectorData( ...
    'data', cell2mat(spikesConv.z), ...
    'description', 'z coordinate'), ...
  'area', types.hdmf_common.VectorData( ...
    'data', spikesConv.areaLabels, ...
    'description', 'Brain area where the unit is located.'), ...
  'lead_id', types.hdmf_common.VectorData( ...
    'data', spikesConv.leadLabels, ...
    'description', 'Lead id where the unit is located'), ...
  'spike_times', spike_times_vector, ...
  'spike_times_index', spike_times_index, ...
  'electrode_group', types.hdmf_common.VectorData( ...
    'data', spikesConv.group, ...
    'description', 'Recording channel groups'), ...
  'waveform_mean', types.hdmf_common.VectorData( ...
    'data', cell2mat(spikesConv.filtWaveform), ...
    'description', ['Mean waveforms on the probe channel with the largest waveform amplitude. ' ...
    'The order that waveforms are stored match the order of units in the unit table.']), ...
  'waveform_sd', types.hdmf_common.VectorData( ...
    'data', cell2mat(spikesConv.filtWaveformSD), ...
    'description', 'Standard deviation of waveforms.'));

% Save the updated file
nwbExport(nwb, options.outputFile);